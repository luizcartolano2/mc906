{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.optimize as opt\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from predict import *\n",
    "from sklearn.metrics import *\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_INPUT = os.getcwd() + '/inputs/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load do dataset de treino e separacao dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load do cvs com o treino feito anteriormente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_treino = pd.read_csv(PATH_INPUT+'training_set_2.csv', usecols=['name','isMarried', 'isNoble','numDeadRelations','popularity','isAlive'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carrega o X e y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = df_treino.iloc[:,1:5]\n",
    "y = df_treino.iloc[:,5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split do dataframe em treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
    "X_validacao, X_test, y_validacao, y_test = train_test_split(X_test, y_test, test_size=0.2, shuffle=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normaliza o X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "std_scale = preprocessing.MinMaxScaler()\n",
    "\n",
    "X_train['numDeadRelations'] = std_scale.fit_transform((X_train['numDeadRelations'].values).reshape((-1,1)))\n",
    "X_train['popularity'] = std_scale.fit_transform((X_train['popularity'].values).reshape((-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validacao['numDeadRelations'] = std_scale.fit_transform((X_validacao['numDeadRelations'].values).reshape((-1,1)))\n",
    "X_validacao['popularity'] = std_scale.fit_transform((X_validacao['popularity'].values).reshape((-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_test['numDeadRelations'] = std_scale.fit_transform((X_test['numDeadRelations'].values).reshape((-1,1)))\n",
    "X_test['popularity'] = std_scale.fit_transform((X_test['popularity'].values).reshape((-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train,X_validacao,X_test,y_train,y_validacao,y_test = X_train.values,X_validacao.values,X_test.values,y_train.values,y_validacao.values,y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Begin building the model framework\n",
    "# Declare the variables that need to be learned and initialization\n",
    "# There are 4 features here, A's dimension is (4, 1)\n",
    "A = tf.Variable(tf.random_normal(shape=[4, 1]))\n",
    "b = tf.Variable(tf.random_normal(shape=[1, 1]))\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define placeholders\n",
    "data = tf.placeholder(dtype=tf.float32, shape=[None, 4])\n",
    "target = tf.placeholder(dtype=tf.float32, shape=[None, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare the model you need to learn\n",
    "mod = tf.matmul(data, A) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare loss function\n",
    "# Use the sigmoid cross-entropy loss function,\n",
    "# first doing a sigmoid on the model result and then using the cross-entropy loss function\n",
    "loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=mod, labels=target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the learning rateï¼Œ batch_size etc.\n",
    "learning_rate = 0.0001\n",
    "batch_size = 5\n",
    "iter_num = 15000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimizer\n",
    "opt = tf.train.GradientDescentOptimizer(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the goal\n",
    "goal = opt.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the accuracy\n",
    "# The default threshold is 0.5, rounded off directly\n",
    "prediction = tf.round(tf.sigmoid(mod))\n",
    "# Bool into float32 type\n",
    "correct = tf.cast(tf.equal(prediction, target), dtype=tf.float32)\n",
    "# Average\n",
    "accuracy = tf.reduce_mean(correct)\n",
    "# End of the definition of the model framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training model\n",
    "# Define the variable that stores the result\n",
    "loss_trace = []\n",
    "train_acc = []\n",
    "test_acc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  300 loss: 0.985438 train_acc: 0.735861 test_acc: 0.778846\n",
      "epoch:  600 loss: 0.544777 train_acc: 0.735861 test_acc: 0.778846\n",
      "epoch:  900 loss: 0.678129 train_acc: 0.735861 test_acc: 0.778846\n",
      "epoch: 1200 loss: 0.516371 train_acc: 0.735861 test_acc: 0.778846\n",
      "epoch: 1500 loss: 0.949077 train_acc: 0.735861 test_acc: 0.778846\n",
      "epoch: 1800 loss: 0.526411 train_acc: 0.735861 test_acc: 0.778846\n",
      "epoch: 2100 loss: 1.079272 train_acc: 0.735861 test_acc: 0.778846\n",
      "epoch: 2400 loss: 0.450789 train_acc: 0.735861 test_acc: 0.778846\n",
      "epoch: 2700 loss: 0.533101 train_acc: 0.735861 test_acc: 0.778846\n",
      "epoch: 3000 loss: 0.318492 train_acc: 0.735861 test_acc: 0.778846\n",
      "epoch: 3300 loss: 0.337722 train_acc: 0.735861 test_acc: 0.778846\n",
      "epoch: 3600 loss: 0.309120 train_acc: 0.735861 test_acc: 0.778846\n",
      "epoch: 3900 loss: 0.830063 train_acc: 0.735861 test_acc: 0.778846\n",
      "epoch: 4200 loss: 0.678227 train_acc: 0.735861 test_acc: 0.778846\n",
      "epoch: 4500 loss: 0.323200 train_acc: 0.735861 test_acc: 0.778846\n",
      "epoch: 4800 loss: 0.705326 train_acc: 0.735861 test_acc: 0.778846\n",
      "epoch: 5100 loss: 0.693043 train_acc: 0.735861 test_acc: 0.778846\n",
      "epoch: 5400 loss: 0.670694 train_acc: 0.735861 test_acc: 0.778846\n",
      "epoch: 5700 loss: 0.702380 train_acc: 0.735861 test_acc: 0.778846\n",
      "epoch: 6000 loss: 0.471970 train_acc: 0.735861 test_acc: 0.778846\n",
      "epoch: 6300 loss: 1.130645 train_acc: 0.735861 test_acc: 0.778846\n",
      "epoch: 6600 loss: 0.435397 train_acc: 0.735861 test_acc: 0.778846\n",
      "epoch: 6900 loss: 0.971910 train_acc: 0.735861 test_acc: 0.778846\n",
      "epoch: 7200 loss: 0.683196 train_acc: 0.735861 test_acc: 0.778846\n",
      "epoch: 7500 loss: 1.031457 train_acc: 0.735861 test_acc: 0.778846\n",
      "epoch: 7800 loss: 0.524985 train_acc: 0.735861 test_acc: 0.778846\n",
      "epoch: 8100 loss: 0.517690 train_acc: 0.735861 test_acc: 0.778846\n",
      "epoch: 8400 loss: 0.830752 train_acc: 0.735861 test_acc: 0.778846\n",
      "epoch: 8700 loss: 0.450243 train_acc: 0.735861 test_acc: 0.778846\n",
      "epoch: 9000 loss: 0.695769 train_acc: 0.735861 test_acc: 0.778846\n",
      "epoch: 9300 loss: 0.452761 train_acc: 0.735861 test_acc: 0.778846\n",
      "epoch: 9600 loss: 0.683351 train_acc: 0.735861 test_acc: 0.778846\n",
      "epoch: 9900 loss: 0.292378 train_acc: 0.735861 test_acc: 0.778846\n",
      "epoch: 10200 loss: 0.522591 train_acc: 0.735861 test_acc: 0.778846\n",
      "epoch: 10500 loss: 0.926321 train_acc: 0.735861 test_acc: 0.778846\n",
      "epoch: 10800 loss: 0.318935 train_acc: 0.735861 test_acc: 0.778846\n",
      "epoch: 11100 loss: 0.367945 train_acc: 0.735861 test_acc: 0.778846\n",
      "epoch: 11400 loss: 0.544324 train_acc: 0.735861 test_acc: 0.778846\n",
      "epoch: 11700 loss: 0.751754 train_acc: 0.735861 test_acc: 0.778846\n",
      "epoch: 12000 loss: 0.443249 train_acc: 0.735861 test_acc: 0.778846\n",
      "epoch: 12300 loss: 0.780992 train_acc: 0.735861 test_acc: 0.778846\n",
      "epoch: 12600 loss: 1.035190 train_acc: 0.735861 test_acc: 0.778846\n",
      "epoch: 12900 loss: 0.873627 train_acc: 0.735861 test_acc: 0.778846\n",
      "epoch: 13200 loss: 0.736315 train_acc: 0.735861 test_acc: 0.778846\n",
      "epoch: 13500 loss: 0.322106 train_acc: 0.735861 test_acc: 0.778846\n",
      "epoch: 13800 loss: 0.532643 train_acc: 0.735861 test_acc: 0.778846\n",
      "epoch: 14100 loss: 0.737148 train_acc: 0.735861 test_acc: 0.778846\n",
      "epoch: 14400 loss: 0.734989 train_acc: 0.735861 test_acc: 0.778846\n",
      "epoch: 14700 loss: 0.726677 train_acc: 0.735861 test_acc: 0.778846\n",
      "epoch: 15000 loss: 0.241872 train_acc: 0.735861 test_acc: 0.778846\n"
     ]
    }
   ],
   "source": [
    "# training model\n",
    "for epoch in range(iter_num):\n",
    "    # Generate random batch index\n",
    "    batch_index = np.random.choice(len(X_train), size=batch_size)\n",
    "    batch_train_X = X_train[batch_index]\n",
    "    batch_train_y = np.matrix(y_train[batch_index])\n",
    "    sess.run(goal, feed_dict={data: batch_train_X, target: batch_train_y})\n",
    "    temp_loss = sess.run(loss, feed_dict={data: batch_train_X, target: batch_train_y})\n",
    "\n",
    "    # convert into a matrix, and the shape of the placeholder to correspond\n",
    "    temp_train_acc = sess.run(accuracy, feed_dict={data: X_train, target: np.matrix(y_train)})\n",
    "    temp_test_acc = sess.run(accuracy, feed_dict={data: X_validacao, target: np.matrix(y_validacao)})\n",
    "    \n",
    "    # recode the result\n",
    "    loss_trace.append(temp_loss)\n",
    "    train_acc.append(temp_train_acc)\n",
    "    test_acc.append(temp_test_acc)\n",
    "    \n",
    "    # output\n",
    "    if (epoch + 1) % 300 == 0:\n",
    "        print('epoch: {:4d} loss: {:5f} train_acc: {:5f} test_acc: {:5f}'.format(epoch + 1, temp_loss, temp_train_acc, temp_test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.08577682],\n",
       "       [-0.41309524],\n",
       "       [ 0.79364973],\n",
       "       [ 0.9717    ]], dtype=float32)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta = sess.run(A)\n",
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.1283875]], dtype=float32)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias = sess.run(b)\n",
    "bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = lambda x_pred: x_pred.dot(theta) + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = sess.run(tf.sigmoid(y_prob(X_validacao)))\n",
    "y_pred = 1 * (y_pred >= 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,  69],\n",
       "       [  0, 243]])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_validacao, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7788461538461539"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_validacao, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = sess.run(tf.sigmoid(y_prob(X_test)))\n",
    "y_pred = 1 * (y_pred >= 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0, 15],\n",
       "       [ 0, 63]])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8076923076923077"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
